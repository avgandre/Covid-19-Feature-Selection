# -*- coding: utf-8 -*-
"""CovidAnonimizado.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CE5wGf7XNRVEPST8-uSLpxh2CKuL3Snu
"""

import pandas as pd
import time
from datetime import timedelta
from sklearn import preprocessing
from sklearn.feature_extraction import FeatureHasher

def BDClima(df):
    #Faz a leitura da base de dados
    dfDataset = pd.read_csv('Datasets/Outros Datasets/INMET.csv', sep=';')
    dfDataset.shape
    dfDataset.head()
    
    #Converte a data para o formato datetime64
    dfDataset['Data'] = pd.to_datetime(dfDataset['Data'], format='%Y/%m/%d', errors='coerce')
    dfDataset['Data'] = dfDataset['Data'] + timedelta(days=3)
    
    #Altera o NaN para 0
    dfDataset = dfDataset.fillna(0)

    #Faz o agrupamento por Data 
    dfDataset = dfDataset.groupby(by=['Data']).agg({
                   'Precipitacao': 'sum', 
                   'Radiacao': ['mean', 'min', 'max'],
                   'Temperatura': ['mean', 'min', 'max'], 
                   'UmidadeHoraria': ['mean', 'min', 'max'], 
                   'Vento': ['mean', 'min', 'max']})
    dfDataset = dfDataset.reset_index()
    
    #Renomeia colunas
    dfDataset.columns = dfDataset.columns.droplevel(1)
    dfDataset.columns = ['Data', 'SomaPrecipitacao', 'MediaRadiacao', 
                  'MinimaRadiacao', 'MaximaRadiacao', 'MediaTemperatura', 
                  'MinimaTemperatura', 'MaximaTemperatura', 'MediaUmidade', 
                  'MinimaUmidade', 'MaximaUmidade', 'MediaVento', 'MinimoVento',
                  'MaximoVento']
    
    #Junta os dados na tabela original
    df = pd.merge(df, dfDataset, how='left', left_on='INICIO_SINTOMAS', 
                  right_on='Data', indicator=False)
    
    #Remove coluna de Data
    df = df.drop(columns=['Data'])
    
    return df

def BDGoogleMobilidade(NomeEntidade, df):
    #Faz a leitura da base de dadosta
    dfDataset = pd.read_csv('Datasets/Outros Datasets/2020_BR_Region_Mobility_Report.csv', 
                     dtype={'iso_3166_2_code': 'string'})
    dfDataset.shape
    dfDataset.head()
    
    #Filtra as cidades pelo código IBGE
    dfDataset = dfDataset[dfDataset['sub_region_2'] == NomeEntidade]
    
    #Converte a data para o formato datetime64
    dfDataset['Data'] = pd.to_datetime(dfDataset['date'])
    dfDataset['Data'] = dfDataset['Data'] + timedelta(days=3)
    
    dfDataset = dfDataset[['Data', 'retail_and_recreation_percent_change_from_baseline',
             'grocery_and_pharmacy_percent_change_from_baseline',
             'parks_percent_change_from_baseline',
             'transit_stations_percent_change_from_baseline',
             'workplaces_percent_change_from_baseline',
             'residential_percent_change_from_baseline']]
    
    #Junta os dados na tabela original
    df = pd.merge(df, dfDataset, how='left', left_on='INICIO_SINTOMAS', 
                  right_on='Data', indicator=False)    
    
    #Remove coluna de Data
    df = df.drop(columns=['Data'])
    
    return df

def BDCompilacaoDecretos(df):
    #Faz a leitura da base de dadosta
    dfDataset = pd.read_csv('Datasets/Outros Datasets/compilacao_decretos_indice.csv', sep=';')
    dfDataset.shape
    dfDataset.head()
    
    #Converte a data para o formato datetime64
    dfDataset['Data'] = pd.to_datetime(dfDataset['Data'], format='%d/%m/%Y', errors='coerce')
    dfDataset['Data'] = dfDataset['Data'] + timedelta(days=3)
    
    #Junta os dados na tabela original
    df = pd.merge(df, dfDataset, how='left', left_on='INICIO_SINTOMAS', 
                  right_on='Data', indicator=False)    
    
    #Remove coluna de Data
    df = df.drop(columns=['Data'])
    
    return df

#Tempo de processamento
tempoInicial = time.time()

#Faz a leitura do arquivo
dados = pd.read_csv('Dados/covid_ajustado.v3.ComSintomas.csv')
dados.shape

#Seleciona as colunas que contém informações
print(dados.isnull().sum().where(lambda x: x < len(dados)).dropna().index)

#Altera o NaN para missing
meusDados = dados.fillna('missing')
meusDados.head()

#Totaliza os dados da coluna Resultado
meusDados.groupby('RESULTADO').size()

#Exclui registros com resultado 'missing'
meusDados = meusDados[meusDados.RESULTADO != 'missing']

#Totaliza os dados das colunas de sintomas
meusDados.groupby('PROF_SAUDE').size()
meusDados.groupby('FEBRE').size()
meusDados.groupby('TOSSE').size()
meusDados.groupby('DOR_GARGANTA').size()
meusDados.groupby('DISPINEIA').size()

#Totaliza os dados das colunas de sintomas considerando apenas as ocorrências com resultdo
meusDados.query('RESULTADO == "confirmado"')[['PROF_SAUDE', 'FEBRE', 'TOSSE', 'DOR_GARGANTA', 'DISPINEIA']]
meusDados.query('RESULTADO == "descartado" or RESULTADO == "confirmado"')['PROF_SAUDE'].value_counts()
meusDados.query('RESULTADO == "descartado" or RESULTADO == "confirmado"')['FEBRE'].value_counts()
meusDados.query('RESULTADO == "descartado" or RESULTADO == "confirmado"')['TOSSE'].value_counts()
meusDados.query('RESULTADO == "descartado" or RESULTADO == "confirmado"')['DOR_GARGANTA'].value_counts()
meusDados.query('RESULTADO == "descartado" or RESULTADO == "confirmado"')['DISPINEIA'].value_counts()

#Exclui registros com sintomas 'missing'
#meusDados = meusDados[meusDados.PROF_SAUDE != 'missing']
meusDados = meusDados[meusDados.FEBRE != 'missing']
meusDados = meusDados[meusDados.DOR_GARGANTA != 'missing']
meusDados = meusDados[meusDados.TOSSE != 'missing']
meusDados = meusDados[meusDados.DISPINEIA != 'missing']
meusDados.shape

#Conta qtos Territorios a base possui
meusDados['TERRITORIO'].value_counts()
len(meusDados.groupby('TERRITORIO').size())

#Conta qtos Subterritorios a base possui
meusDados['SUBTERRITORIO'].value_counts()
len(meusDados['SUBTERRITORIO'].value_counts())

#Faz um sumário dos dados de todas colunas
for coluna in meusDados.columns:
  print('Coluna: ', coluna)
  print(meusDados[coluna].value_counts())
  print('')

#Totaliza os dados da coluna Resultado por Território
meusDados.query('RESULTADO == "confirmado"')['TERRITORIO'].value_counts()

#Mostra uma breve descrição dos dados do Bairro
meusDados['TERRITORIO'].describe()

#Transforma str para date
meusDados['INICIO_SINTOMAS'] = pd.to_datetime(meusDados['INICIO_SINTOMAS'], errors='coerce')
meusDados['DATA_NOTIFICACAO'] = pd.to_datetime(meusDados['DATA_NOTIFICACAO'], errors='coerce')

#Exclui casos que não conseguiu converter a data
meusDados = meusDados.dropna(subset=['INICIO_SINTOMAS'])
meusDados = meusDados.dropna(subset=['DATA_NOTIFICACAO'])
meusDados.shape

###Faz a totalização dos casos confirmados por Território ###
confirmadosPorTerritorio = meusDados[['TERRITORIO', 'INICIO_SINTOMAS', 'RESULTADO']].query('RESULTADO == "confirmado"')
confirmadosPorTerritorio = pd.merge(meusDados, confirmadosPorTerritorio, how='left', on=['TERRITORIO', 'TERRITORIO'], suffixes=('_t1', '_t2'))

print(confirmadosPorTerritorio.shape)
confirmadosPorTerritorio.head()

confirmadosPorTerritorio['Diferenca_dias_sintomas'] = (confirmadosPorTerritorio['INICIO_SINTOMAS_t1'] - confirmadosPorTerritorio['INICIO_SINTOMAS_t2']).dt.days
confirmadosPorTerritorio = confirmadosPorTerritorio[(confirmadosPorTerritorio.Diferenca_dias_sintomas >= 0) & (confirmadosPorTerritorio.Diferenca_dias_sintomas <= 13)]
confirmadosPorTerritorio.head()

confirmados14Dias = confirmadosPorTerritorio.groupby(['ID']).size()
confirmados14Dias

###Faz a totalização dos casos descartados por Território ###
descartadosPorTerritorio = meusDados[['TERRITORIO', 'INICIO_SINTOMAS', 'RESULTADO']].query('RESULTADO == "descartado"')
descartadosPorTerritorio = pd.merge(meusDados, descartadosPorTerritorio, how='left', on=['TERRITORIO', 'TERRITORIO'], suffixes=('_t1', '_t2'))

print(descartadosPorTerritorio.shape)
descartadosPorTerritorio.head()

descartadosPorTerritorio['Diferenca_dias_sintomas'] = (descartadosPorTerritorio['INICIO_SINTOMAS_t1'] - descartadosPorTerritorio['INICIO_SINTOMAS_t2']).dt.days
descartadosPorTerritorio = descartadosPorTerritorio[(descartadosPorTerritorio.Diferenca_dias_sintomas >= 0)]
descartadosPorTerritorio.head()

descartados = descartadosPorTerritorio.groupby(['ID']).size()
descartados

###Faz a totalização dos casos removidos por Território ###
removidosPorTerritorio = meusDados[['TERRITORIO', 'INICIO_SINTOMAS', 'RESULTADO']].query('RESULTADO == "confirmado"')
removidosPorTerritorio = pd.merge(meusDados, removidosPorTerritorio, how='left', on=['TERRITORIO', 'TERRITORIO'], suffixes=('_t1', '_t2'))

print(removidosPorTerritorio.shape)
removidosPorTerritorio.head()

removidosPorTerritorio['Diferenca_dias_sintomas'] = (removidosPorTerritorio['INICIO_SINTOMAS_t1'] - removidosPorTerritorio['INICIO_SINTOMAS_t2']).dt.days
removidosPorTerritorio = removidosPorTerritorio[(removidosPorTerritorio.Diferenca_dias_sintomas >= 14)]
removidosPorTerritorio.head()

removidos = removidosPorTerritorio.groupby(['ID']).size()
removidos

###Junta os dados na tabela original ###
df = pd.merge(meusDados, pd.DataFrame(confirmados14Dias, columns=['Confirmados_territorio_14dias']), 
              how='left', on=['ID', 'ID'])
df = pd.merge(df, pd.DataFrame(descartados, columns=['Descartados_territorio']), 
              how='left', on=['ID', 'ID'])
df = pd.merge(df, pd.DataFrame(removidos, columns=['Removidos_territorio']), how='left', 
              on=['ID', 'ID'])

###Faz a totalização dos casos confirmados por Subterritório ###
#confirmadosPorSubterritorio = meusDados[['SUBTERRITORIO', 'INICIO_SINTOMAS', 'RESULTADO']].query('RESULTADO == "confirmado"')
#confirmadosPorSubterritorio = pd.merge(meusDados, confirmadosPorSubterritorio, how='left', on=['SUBTERRITORIO', 'SUBTERRITORIO'], suffixes=('_t1', '_t2'))

#print(confirmadosPorSubterritorio.shape)
#confirmadosPorSubterritorio.head()

#confirmadosPorSubterritorio['Diferenca_dias_sintomas'] = (confirmadosPorSubterritorio['INICIO_SINTOMAS_t1'] - confirmadosPorSubterritorio['INICIO_SINTOMAS_t2']).dt.days
#confirmadosPorSubterritorio = confirmadosPorSubterritorio[(confirmadosPorSubterritorio.Diferenca_dias_sintomas >= 0) & (confirmadosPorSubterritorio.Diferenca_dias_sintomas <= 13)]
#confirmadosPorSubterritorio.head()

#confirmadosSub14Dias = confirmadosPorSubterritorio.groupby(['ID']).size()
#confirmadosSub14Dias

###Faz a totalização dos casos descartados por Subterritório ###
#descartadosPorSubterritorio = meusDados[['SUBTERRITORIO', 'INICIO_SINTOMAS', 'RESULTADO']].query('RESULTADO == "descartado"')
#descartadosPorSubterritorio = pd.merge(meusDados, descartadosPorSubterritorio, how='left', on=['SUBTERRITORIO', 'SUBTERRITORIO'], suffixes=('_t1', '_t2'))

#print(descartadosPorSubterritorio.shape)
#descartadosPorSubterritorio.head()

#descartadosPorSubterritorio['Diferenca_dias_sintomas'] = (descartadosPorSubterritorio['INICIO_SINTOMAS_t1'] - descartadosPorSubterritorio['INICIO_SINTOMAS_t2']).dt.days
#descartadosPorSubterritorio = descartadosPorSubterritorio[(descartadosPorSubterritorio.Diferenca_dias_sintomas >= 0)]
#descartadosPorSubterritorio.head()

#descartadosSub = descartadosPorSubterritorio.groupby(['ID']).size()
#descartadosSub

###Faz a totalização dos casos removidos por Subterritório ###
#removidosPorSubterritorio = meusDados[['SUBTERRITORIO', 'INICIO_SINTOMAS', 'RESULTADO']].query('RESULTADO == "confirmado"')
#removidosPorSubterritorio = pd.merge(meusDados, removidosPorSubterritorio, how='left', on=['SUBTERRITORIO', 'SUBTERRITORIO'], suffixes=('_t1', '_t2'))

#print(removidosPorSubterritorio.shape)
#removidosPorSubterritorio.head()

#removidosPorSubterritorio['Diferenca_dias_sintomas'] = (removidosPorSubterritorio['INICIO_SINTOMAS_t1'] - removidosPorSubterritorio['INICIO_SINTOMAS_t2']).dt.days
#removidosPorSubterritorio = removidosPorSubterritorio[(removidosPorSubterritorio.Diferenca_dias_sintomas >= 14)]
#removidosPorSubterritorio.head()

#removidosSub = removidosPorSubterritorio.groupby(['ID']).size()
#removidosSub

###Junta os dados na tabela original ###
#df = pd.merge(df, pd.DataFrame(confirmadosSub14Dias, columns=['Confirmados_subterritorio_14dias']), 
#              how='left', on=['ID', 'ID'])
#df = pd.merge(df, pd.DataFrame(descartadosSub, columns=['Descartados_subterritorio']), 
#              how='left', on=['ID', 'ID'])
#df = pd.merge(df, pd.DataFrame(removidosSub, columns=['Removidos_subterritorio']), how='left', 
#              on=['ID', 'ID'])

df.head()
df.columns

#df.query('TERRITORIO == "cs_centro"').sort_values(by=['INICIO_SINTOMAS']).head(5)

#Define pra zero os registros com valor nulo
df.loc[df[df.Confirmados_territorio_14dias.isnull()].index, ['Confirmados_territorio_14dias']] = 0
df.loc[df[df.Descartados_territorio.isnull()].index, ['Descartados_territorio']] = 0
df.loc[df[df.Removidos_territorio.isnull()].index, ['Removidos_territorio']] = 0

#df.loc[df[df.Confirmados_subterritorio_14dias.isnull()].index, ['Confirmados_subterritorio_14dias']] = 0
#df.loc[df[df.Descartados_subterritorio.isnull()].index, ['Descartados_subterritorio']] = 0
#df.loc[df[df.Removidos_subterritorio.isnull()].index, ['Removidos_subterritorio']] = 0

df['Tx_Confirmados_territorio_14dias'] = df['Confirmados_territorio_14dias'] / df['populacao']
df['Tx_Descartados_territorio'] = df['Descartados_territorio'] / df['populacao']
df['Tx_Removidos_territorio'] = df['Removidos_territorio'] / df['populacao']

#Join com outros datasets
df = BDClima(df)

df = BDGoogleMobilidade('Florianópolis', df)

df = BDCompilacaoDecretos(df)

#Exclui registros com Sexo 'missing'
df = df.drop(df[df.SEXO == 'missing'].index)

#Reset no índice para dar append nas colunas
df = df.reset_index()

#Transforma Resultado em código
df['RESULTADO'] = df['RESULTADO'].apply(lambda x: '0' if (x == 'descartado') else ('1' if x == 'confirmado' else '2'))

#Transforma 'Início sintomas' em timestamp
df['INICIO_SINTOMAS'].isnull().sum()
df['INICIO_SINTOMAS'] = df['INICIO_SINTOMAS'].apply(lambda x: int(time.mktime(x.timetuple())))

#Transforma 'Data notificação' em timestamp
df['DATA_NOTIFICACAO'].isnull().sum()
df['DATA_NOTIFICACAO'] = df['DATA_NOTIFICACAO'].apply(lambda x: int(time.mktime(x.timetuple())))

# Formata a Idade com duas casas decimais
df['IDADE'] = df['IDADE'].map('{:,.2f}'.format)

#Transforma Sexo em código
df['SEXO'] = df['SEXO'].apply(lambda x: '0' if (x == 'f') else '1')

#Transforma Territorio em hash
len(df.groupby('TERRITORIO').size())
fh = FeatureHasher(n_features=20, input_type='string')
hashTerritorio = fh.fit_transform(df['TERRITORIO'])
dfTerritorio = pd.DataFrame(fh.fit_transform(df['TERRITORIO']).toarray(), 
                            columns=['hf0', 'hf1', 'hf2', 'hf3', 'hf4', 'hf5', 'hf6', 'hf7', 'hf8', 'hf9',
                                     'hf10', 'hf11', 'hf12', 'hf13', 'hf14', 'hf15', 'hf16', 'hf17', 'hf18', 'hf19'])
df[dfTerritorio.columns] = dfTerritorio

#Transforma Subterritorio em hash
len(df.groupby('SUBTERRITORIO').size())
fh = FeatureHasher(n_features=20, input_type='string')
hashTerritorio = fh.fit_transform(df['SUBTERRITORIO'])
dfSubterritorio = pd.DataFrame(fh.fit_transform(df['SUBTERRITORIO']).toarray(), 
                               columns=['st0', 'st1', 'st2', 'st3', 'st4', 'st5', 'st6', 'st7', 'st8', 'st9', 
                                        'st10', 'st11', 'st12', 'st13', 'st14', 'st15', 'st16', 'st17', 'st18', 'st19'])
df[dfSubterritorio.columns] = dfSubterritorio

#Transforma 'Profissional saúde' em código
#len(df.groupby('PROF_SAUDE').size())
#df.groupby('PROF_SAUDE').size()
#dfProfissionalSaude = pd.DataFrame(preprocessing.OneHotEncoder().fit_transform(df['PROF_SAUDE'].
#                                   to_frame()).toarray(), columns=['ps0', 'ps1'])
#df[dfProfissionalSaude.columns] = dfProfissionalSaude

#Transforma 'Dor garganta' em código
len(df.groupby('DOR_GARGANTA').size())
df.groupby('DOR_GARGANTA').size()
dfDorGarganta = pd.DataFrame(preprocessing.OneHotEncoder().fit_transform(df['DOR_GARGANTA'].
                             to_frame()).toarray(), columns=['dg0', 'dg1'])
df[dfDorGarganta.columns] = dfDorGarganta

#Transforma 'Dispinéia' em código
len(df.groupby('DISPINEIA').size())
df.groupby('DISPINEIA').size()
dfDispineia = pd.DataFrame(preprocessing.OneHotEncoder().fit_transform(df['DISPINEIA'].to_frame()).
                           toarray(), columns=['dp0', 'dp1'])
df[dfDispineia.columns] = dfDispineia

#Transforma 'Febre' em código
len(df.groupby('FEBRE').size())
df.groupby('FEBRE').size()
dfFebre = pd.DataFrame(preprocessing.OneHotEncoder().fit_transform(df['FEBRE'].to_frame()).
                       toarray(), columns=['fb0', 'fb1'])
df[dfFebre.columns] = dfFebre

#Transforma 'Tosse' em código
len(df.groupby('TOSSE').size())
df.groupby('TOSSE').size()
dfTosse = pd.DataFrame(preprocessing.OneHotEncoder().fit_transform(df['TOSSE'].to_frame()).
                       toarray(), columns=['ts0', 'ts1'])
df[dfTosse.columns] = dfTosse

#Transforma 'Tipo exame' em código
#len(df.groupby('TIPO_EXAME').size())
#df['TIPO_EXAME'].value_counts()
#enc = preprocessing.OneHotEncoder()
#dfTipoExame = pd.DataFrame(preprocessing.OneHotEncoder().fit_transform(df['TIPO_EXAME'].to_frame()).
#                           toarray(), columns=['te0', 'te1', 'te2', 'te3', 'te4'])
#df[dfTipoExame.columns] = dfTipoExame

#Transforma Raça em código
len(df.groupby('RACA_COR').size())
df['RACA_COR'].value_counts()
enc = preprocessing.OneHotEncoder()
dfRacaCor = pd.DataFrame(preprocessing.OneHotEncoder().fit_transform(df['RACA_COR'].to_frame()).
                         toarray(), columns=['rc0', 'rc1', 'rc2', 'rc3', 'rc4'])
df[dfRacaCor.columns] = dfRacaCor

#Transforma 'Faixa etária' em código
len(df.groupby('FAIXA_ETARIA').size())
df['FAIXA_ETARIA'].value_counts()
enc = preprocessing.OneHotEncoder()
dfFaixaEtaria = pd.DataFrame(preprocessing.OneHotEncoder().fit_transform(df['FAIXA_ETARIA'].
                             to_frame()).toarray(), columns=['fe0', 'fe1', 'fe2', 'fe3', 'fe4', 'fe5'])
df[dfFaixaEtaria.columns] = dfFaixaEtaria

#Transforma Triagem em código
len(df.groupby('TRIAGEM').size())
df.groupby('TRIAGEM').size()
dfTriagem = pd.DataFrame(preprocessing.OneHotEncoder().fit_transform(df['TRIAGEM'].to_frame()).
                         toarray(), columns=['tr0', 'tr1', 'tr2'])
df[dfTriagem.columns] = dfTriagem

#Retira algumas colunas
df = df.drop(columns=['index', 'ID', 'TERRITORIO', 'SUBTERRITORIO', 'TRIAGEM', 'FAIXA_ETARIA', 
                      'RACA_COR', 'PROF_SAUDE', 'DOR_GARGANTA', 'DISPINEIA', 'FEBRE', 'TOSSE', 
                      'TIPO_EXAME', 'INFECTADOS_TERRITORIO', 'TX_INFECTADOS_TERRITORIO'])
df.to_csv('Dados/novo_covid_ajustado_com_sintomas2.csv', index=False, header=True)

print("\n--- %.2f minutos ---" % ((time.time() - tempoInicial) / 60))
